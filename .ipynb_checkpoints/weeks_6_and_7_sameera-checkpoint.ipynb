{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CGc6Y5_eKaPD"
   },
   "source": [
    "**SOW-MKI49: Neural Information Processing Systems**  \n",
    "*Weeks 6 and 7: Assignment (100 points + 20 bonus points)  \n",
    "Author: Luca and Umut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cBlzrHdoKzvY"
   },
   "source": [
    "# Group number: 17\n",
    "\n",
    "1. Sameera Sandaruwan, s1014012\n",
    "2. Mohit Jethwani, s1019474"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "---\n",
    "http://kvfrans.com/variational-autoencoders-explained/\n",
    "\n",
    "However, there were a couple of downsides to using a plain GAN.\n",
    "\n",
    "First, the images are generated off some arbitrary noise. If you wanted to generate a picture with specific features, there's no way of determining which initial noise values would produce that picture, other than searching over the entire distribution.\n",
    "\n",
    "Second, a generative adversarial model only discriminates between \"real\" and \"fake\" images. There's no constraints that an image of a cat has to look like a cat. This leads to results where there's no actual object in a generated image, but the style just looks like picture.\n",
    "\n",
    "In this post, I'll go over the variational autoencoder, a type of network that solves these two problems.\n",
    "\n",
    "The more efficiently we can encode the original image, the higher we can raise the standard deviation on our gaussian until it reaches one.\n",
    "\n",
    "https://github.com/chainer/chainer/blob/master/examples/vae/net.py\n",
    "\n",
    "https://github.com/musyoku/variational-autoencoder/blob/master/vae_m1.py\n",
    "\n",
    "---\n",
    "## To Do\n",
    "\n",
    "1. Search Variational autoencoder\n",
    "2. Search Variational inference\n",
    "3. Find Input and Output dimensions of dataset: \n",
    "Depends on our Network architecture. Network can be Convolutional (input is 28x28, output 1x10) or Linear (input is 1x784, output 1x10)\n",
    "4. Check the architecture\n",
    "5. How the loss function work here\n",
    "6. figure out the architecture and what (X, Y, Z) are\n",
    "7. Unit gaussian distribution\n",
    "\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gz0FZAwiJ-al"
   },
   "outputs": [],
   "source": [
    "from chainer import cuda, datasets, serializers\n",
    "from chainer.dataset import DatasetMixin, concat_examples\n",
    "from chainer.iterators import MultithreadIterator\n",
    "from chainer.iterators import SerialIterator\n",
    "from chainer.optimizers import Adam, SGD, RMSprop\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import cupy\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "model_directory = 'Model'\n",
    "train_session = 'ADAM_100'\n",
    "device = 0\n",
    "\n",
    "# optimizer = Adam()\n",
    "optimizer = Adam(alpha=0.001, beta1=0.9, beta2=0.999, eps=1e-08)\n",
    "# optimizer = SGD(lr=1e-3)\n",
    "# optimizer = RMSprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ckO0T0SLAFf7"
   },
   "source": [
    "# Decoder\n",
    "This is the decoder class. It transforms **latents (features) to observables (images)**. It corresponds to p(x | z) in the context of **variational inference** (and the slides), **where x is observables and y is latents.**\n",
    "\n",
    "Task: (10 points)\n",
    "\n",
    "- Implement the decoder class for a **variational autoencoder**. Note that the **decoder** should output the **Gaussian distribution parameters (mean and variance per pixel)** of images rather than images themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ew8VZCkl-FdE"
   },
   "outputs": [],
   "source": [
    "class Decoder(chainer.ChainList):\n",
    "    def __init__(self): # <= you might want to pass some architecture parameters (e.g., #i/o units, etc.) here\n",
    "        super(Decoder, self).__init__(\n",
    "            # pass your decoder layers here\n",
    "            L.Linear(10, 500),\n",
    "            \n",
    "            L.Linear(500, 1024),\n",
    "            L.Linear(1024, 1024),\n",
    "            \n",
    "            L.Linear(1024, 784),\n",
    "            L.Linear(1024, 784),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self[0](x))\n",
    "        h = F.relu(self[1](h))\n",
    "        h = F.relu(self[2](h))\n",
    "        mean_x = F.softmax(self[-2](h))\n",
    "        ln_var_x = F.softmax(self[-1](h))\n",
    "        \n",
    "        return mean_x, ln_var_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d36RjWO6AKqO"
   },
   "source": [
    "# Encoder\n",
    "This is the encoder class. It transforms **observables (images) to latents (features)**. It corresponds to **q(z|x)** in the context of variational inference (and the slides), **where z is latents and x is observables**.\n",
    "\n",
    "Task: (10 points)\n",
    "\n",
    "- Implement the encoder class for a variational autoencoder. Note that the encoder should output the Gaussian distribution parameters (mean and variance per feature) of features rather than features themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V-5xcJAWAFIC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhttps://www.kaggle.com/luyujia/mnist-chainer-cnn#\\ncheck this - https://github.com/musyoku/variational-autoencoder/blob/master/vae_m1.py\\n\\nConvolutional Encoder  - backup\\nconv1 = L.Convolution2D(in_channels=1, out_channels=32, ksize=5),\\nconv2 = L.Convolution2D(in_channels=32, out_channels=64, ksize=5),\\nmean_z = L.Linear(1024, 10),\\nln_var_z = L.Linear(1024, 10),\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Encoder(chainer.ChainList):\n",
    "    def __init__(self): # <= you might want to pass some architecture parameters (e.g., #i/o units, etc.) here\n",
    "        super(Encoder, self).__init__(\n",
    "            # pass your encoder layers here\n",
    "            L.Linear(784, 1024),\n",
    "            \n",
    "            L.Linear(1024, 1024),\n",
    "            L.Linear(1024, 500),\n",
    "            \n",
    "            L.Linear(500, 10),\n",
    "            L.Linear(500, 10),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self[0](x))\n",
    "        h = F.relu(self[1](h))\n",
    "        h = F.relu(self[2](h))\n",
    "        mean_z = self[-2](h)\n",
    "        ln_var_z = self[-1](h)\n",
    "        \n",
    "        return mean_z, ln_var_z\n",
    "'''\n",
    "https://www.kaggle.com/luyujia/mnist-chainer-cnn#\n",
    "check this - https://github.com/musyoku/variational-autoencoder/blob/master/vae_m1.py\n",
    "\n",
    "Convolutional Encoder  - backup\n",
    "conv1 = L.Convolution2D(in_channels=1, out_channels=32, ksize=5),\n",
    "conv2 = L.Convolution2D(in_channels=32, out_channels=64, ksize=5),\n",
    "mean_z = L.Linear(1024, 10),\n",
    "ln_var_z = L.Linear(1024, 10),\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ch2iPFbBWVu"
   },
   "source": [
    "# Loss\n",
    "This is the loss class. The loss of encoder and decoder of a variational autoencoder is the evidence lower bound as follows:\n",
    "\n",
    "$L = D_{KL}(q(z | x), p(z)) -  E_{z\\sim q}[log~p(x | z)]$\n",
    "\n",
    "The first term above is the KL divergence between the approximate posterior (q) and the prior (p), which can be interpreted as a form of regularization. You can assume that the prior is unit Gaussian. It can be implemented with the F.gaussian_kl_divergence function in Chainer.\n",
    "\n",
    "The second term above is the Gaussian negative log likelihood. This is the term that fits the data, which is very similar to the usual loss functions that you use in deep learning. It can be implemented with the F.gaussian_nll function in Chainer.\n",
    "\n",
    "Task: \n",
    "\n",
    "- Implement the loss class. (10 points)\n",
    "\n",
    "\n",
    "As input, it gets the following arguments:\n",
    "\n",
    "mean_z => mean of the encoded features (output of the encoder)  \n",
    "ln_var_z => log variance of the encoded features (output of the encoder)  \n",
    "x => input images (mini batch)  \n",
    "mean_x => mean of the decoded images (output of the decoder)  \n",
    "ln_var_x => mean of the decoded images (output of the decoder)  \n",
    "\n",
    "As output, it gives the loss.\n",
    "\n",
    "- Explain why we use log variance instead of variance. (5 points)\n",
    "\n",
    "**Answer**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# z_mean and z_stddev are two vectors generated by encoder network\\nlatent_loss = 0.5 * tf.reduce_sum(tf.square(z_mean) + tf.square(z_stddev) - tf.log(tf.square(z_stddev)) - 1,1) \\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# z_mean and z_stddev are two vectors generated by encoder network\n",
    "latent_loss = 0.5 * tf.reduce_sum(tf.square(z_mean) + tf.square(z_stddev) - tf.log(tf.square(z_stddev)) - 1,1) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iN6gKfG9BWfC"
   },
   "outputs": [],
   "source": [
    "# check this - https://github.com/musyoku/variational-autoencoder/blob/master/vae_m1.py\n",
    "# https://wiseodd.github.io/techblog/2016/12/10/variational-autoencoder/\n",
    "# https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf\n",
    "class Loss(object):\n",
    "    def __call__(self, mean_z, ln_var_z, x, mean_x, ln_var_x):\n",
    "        # Implement the loss here     \n",
    "        '''\n",
    "        1. KL divergence\n",
    "        F.gaussian_kl_divergence\n",
    "        \n",
    "        𝐷𝐾𝐿(𝑞(𝑧|𝑥),𝑝(𝑧))\n",
    "        \n",
    "        '''\n",
    "        dkl = F.gaussian_kl_divergence(mean_z, ln_var_z)\n",
    "        '''\n",
    "        2. Gaussian negative log likelihood\n",
    "        F.gaussian_nll\n",
    "        \n",
    "        𝐸𝑧∼𝑞[𝑙𝑜𝑔(𝑝(𝑥|𝑧))]\n",
    "        \n",
    "        '''\n",
    "        Gnll = F.gaussian_nll(x, mean_x, ln_var_x)\n",
    "#         print('loss ', dkl, Gnll)\n",
    "        return dkl + Gnll\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wuS4ynBqBYt9"
   },
   "source": [
    "# Model\n",
    "This is the model class. It combines the encoder and the decoder.\n",
    "\n",
    "Task: (20 points)\n",
    "\n",
    "- Implement the reparameterziation trick for sampling latents. (10 points)\n",
    "\n",
    "\n",
    "\n",
    "- Explain why we need to use this trick. (10 points)\n",
    "\n",
    "**The latent loss, which is the KL divergence that measures how closely the latent variables match a unit gaussian. In order to optimize the KL divergence, we need the trick: instead of the encoder generating a vector of real values, it will generate a vector of means and a vector of standard deviations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kTLyWlw2BY3H"
   },
   "outputs": [],
   "source": [
    "class Model(chainer.Chain):\n",
    "    def __init__(self, decoder, encoder):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        with self.init_scope():\n",
    "            self.decoder = decoder\n",
    "            self.encoder = encoder\n",
    "\n",
    "    def __call__(self, x):\n",
    "        mean_z, ln_var_z = self.encoder(x)\n",
    "        \n",
    "        # Sample latents (z) from the Gaussian with parameters ln_var_z, mean_z by using the reparameterization trick\n",
    "        '''\n",
    "        https://www.jeremyjordan.me/variational-autoencoders/\n",
    "        we can just sample from the standard deviations and add the mean, and use that as our latent vector: \n",
    "        samples = tf.random_normal([batchsize,n_z],0,1,dtype=tf.float32)  \n",
    "        sampled_z = z_mean + (z_stddev * samples)\n",
    "        '''\n",
    "        z = np.random.normal(0, 1, 10) if device < 0 else cupy.random.normal(0, 1, 10)\n",
    "#         print(ln_var_z)\n",
    "        stddev_z = np.sqrt(ln_var_z) if device < 0 else np.sqrt(ln_var_z.data.get())\n",
    "        if device == 0:\n",
    "            stddev_z = cupy.asarray(stddev_z)\n",
    "#         print(stddev_z)\n",
    "        z = mean_z + (ln_var_z * z)\n",
    "        mean_x, ln_var_x = self.decoder(z)\n",
    "\n",
    "        return mean_z, ln_var_z, x, mean_x, ln_var_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6UYXDr2-HrrA"
   },
   "source": [
    "This is a helper class to use the Mnist dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "12AV4tiBHo0W"
   },
   "outputs": [],
   "source": [
    "class Mnist(DatasetMixin):\n",
    "    def __init__(self):\n",
    "        self.dataset = datasets.get_mnist(False)[0 if chainer.config.train else 1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def get_example(self, i):\n",
    "        return self.dataset[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tC5HdWquIw7B"
   },
   "source": [
    "Task: (50 points)\n",
    "\n",
    "- Train the above defined variational autoencoder on the Mnist dataset. You can refer to the earlier assignments to implement your training loop. (25 points)\n",
    "\n",
    "- How good are the samples? Randomy sample some digits and visualize them. (10 points)\n",
    "\n",
    "- How good are the reconstructions? Draw an Mnist like digit, encode it, decode it and visualize the digits. How different is the reconstruction from the original. (10 points)\n",
    "\n",
    "- Repeat the last task but by drawing something other than a digit (e.g., a face). How accuracte is the reconstructions? Explain the results. (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I34eP98AIV-j"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()\n",
    "decoder = Decoder()\n",
    "model = Model(decoder, encoder) if device < 0 else Model(decoder, encoder).to_gpu(device)\n",
    "\n",
    "optimizer.setup(model)\n",
    "\n",
    "### Prep dataset\n",
    "batch_size = 100\n",
    "training_set = Mnist()\n",
    "training_iterator = SerialIterator(training_set, batch_size, False, True)\n",
    "loss_history = {'training': [], 'validation': []}\n",
    "\n",
    "lossFunc = Loss()\n",
    "\n",
    "epochs_start = 0\n",
    "epochs_end = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sameera/anaconda3/envs/NIPS/lib/python3.6/site-packages/ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> train | epoch = 0 | time= 10.040664196014404 sec | loss= 76380.86584635417\n",
      ">>> train | epoch = 1 | time= 8.055435180664062 sec | loss= 76366.01225260417\n",
      ">>> train | epoch = 2 | time= 8.038763046264648 sec | loss= 76361.6991796875\n",
      ">>> train | epoch = 3 | time= 10.619808912277222 sec | loss= 76358.80063802084\n",
      ">>> train | epoch = 4 | time= 10.544224739074707 sec | loss= 76357.04944010417\n",
      ">>> train | epoch = 5 | time= 8.279929876327515 sec | loss= 76355.87223958333\n",
      ">>> train | epoch = 6 | time= 8.0580153465271 sec | loss= 76354.7480859375\n",
      ">>> train | epoch = 7 | time= 10.318510293960571 sec | loss= 76353.95135416667\n",
      ">>> train | epoch = 8 | time= 10.365249872207642 sec | loss= 76353.53895833333\n",
      ">>> train | epoch = 9 | time= 10.87803316116333 sec | loss= 76353.10690104167\n",
      ">>> train | epoch = 10 | time= 8.525885820388794 sec | loss= 76352.10953125\n",
      ">>> train | epoch = 11 | time= 11.128168106079102 sec | loss= 76352.033671875\n",
      ">>> train | epoch = 12 | time= 11.13048791885376 sec | loss= 76351.49919270833\n",
      ">>> train | epoch = 13 | time= 10.588587284088135 sec | loss= 76351.41111979166\n",
      ">>> train | epoch = 14 | time= 10.589146375656128 sec | loss= 76351.1999609375\n",
      ">>> train | epoch = 15 | time= 8.06975269317627 sec | loss= 76350.94305989583\n",
      ">>> train | epoch = 16 | time= 8.03885555267334 sec | loss= 76350.8464453125\n",
      ">>> train | epoch = 17 | time= 8.06398630142212 sec | loss= 76350.66087239583\n",
      ">>> train | epoch = 18 | time= 8.06261920928955 sec | loss= 76350.65858072917\n",
      ">>> train | epoch = 19 | time= 8.094516277313232 sec | loss= 76350.2978125\n",
      ">>> train | epoch = 20 | time= 12.314541578292847 sec | loss= 76350.36290364583\n",
      ">>> train | epoch = 21 | time= 11.934011936187744 sec | loss= 76350.00640625\n",
      ">>> train | epoch = 22 | time= 11.387839317321777 sec | loss= 76349.93755208333\n",
      ">>> train | epoch = 23 | time= 11.074042797088623 sec | loss= 76349.88145833333\n",
      ">>> train | epoch = 24 | time= 10.859747886657715 sec | loss= 76349.57151041667\n",
      ">>> train | epoch = 25 | time= 10.64933443069458 sec | loss= 76349.5984765625\n",
      ">>> train | epoch = 26 | time= 10.762793779373169 sec | loss= 76349.68725260417\n",
      ">>> train | epoch = 27 | time= 11.270459651947021 sec | loss= 76349.43328125\n",
      ">>> train | epoch = 28 | time= 11.447173118591309 sec | loss= 76349.55919270833\n",
      ">>> train | epoch = 29 | time= 10.991834163665771 sec | loss= 76349.28328125\n",
      ">>> train | epoch = 30 | time= 10.933913707733154 sec | loss= 76349.17040364584\n",
      ">>> train | epoch = 31 | time= 10.732000589370728 sec | loss= 76349.30048177083\n",
      ">>> train | epoch = 32 | time= 10.976815462112427 sec | loss= 76349.11135416667\n",
      ">>> train | epoch = 33 | time= 10.568314552307129 sec | loss= 76349.1455859375\n",
      ">>> train | epoch = 34 | time= 10.68183946609497 sec | loss= 76349.07169270833\n",
      ">>> train | epoch = 35 | time= 11.285498142242432 sec | loss= 76348.99361979167\n",
      ">>> train | epoch = 36 | time= 11.102977275848389 sec | loss= 76348.8321484375\n",
      ">>> train | epoch = 37 | time= 10.409046173095703 sec | loss= 76348.94442708333\n",
      ">>> train | epoch = 38 | time= 10.88545536994934 sec | loss= 76348.694140625\n",
      ">>> train | epoch = 39 | time= 10.985615730285645 sec | loss= 76348.72162760417\n",
      ">>> train | epoch = 40 | time= 10.592121124267578 sec | loss= 76348.73733072917\n",
      ">>> train | epoch = 41 | time= 10.629303693771362 sec | loss= 76348.51838541667\n",
      ">>> train | epoch = 42 | time= 10.606343746185303 sec | loss= 76348.66850260417\n",
      ">>> train | epoch = 43 | time= 9.433048009872437 sec | loss= 76348.55748697916\n",
      ">>> train | epoch = 44 | time= 9.4648118019104 sec | loss= 76348.4694921875\n",
      ">>> train | epoch = 45 | time= 9.502289533615112 sec | loss= 76348.52932291667\n",
      ">>> train | epoch = 46 | time= 8.162692785263062 sec | loss= 76348.34421875\n",
      ">>> train | epoch = 47 | time= 8.227524518966675 sec | loss= 76348.63048177083\n",
      ">>> train | epoch = 48 | time= 8.954899072647095 sec | loss= 76348.36001302084\n",
      ">>> train | epoch = 49 | time= 9.605375051498413 sec | loss= 76348.207421875\n",
      ">>> train | epoch = 50 | time= 11.168386220932007 sec | loss= 76348.2594921875\n",
      ">>> train | epoch = 51 | time= 11.079232931137085 sec | loss= 76348.36428385417\n",
      ">>> train | epoch = 52 | time= 11.108179807662964 sec | loss= 76348.30666666667\n",
      ">>> train | epoch = 53 | time= 11.24850583076477 sec | loss= 76348.24020833333\n",
      ">>> train | epoch = 54 | time= 10.896552085876465 sec | loss= 76348.113359375\n",
      ">>> train | epoch = 55 | time= 11.12076473236084 sec | loss= 76348.20104166666\n",
      ">>> train | epoch = 56 | time= 12.179479837417603 sec | loss= 76348.29649739583\n",
      ">>> train | epoch = 57 | time= 10.65464448928833 sec | loss= 76348.020390625\n",
      ">>> train | epoch = 58 | time= 11.521619081497192 sec | loss= 76348.01873697917\n",
      ">>> train | epoch = 59 | time= 11.656968832015991 sec | loss= 76348.0871484375\n",
      ">>> train | epoch = 60 | time= 11.215214967727661 sec | loss= 76348.032890625\n",
      ">>> train | epoch = 61 | time= 8.743142366409302 sec | loss= 76347.9052734375\n",
      ">>> train | epoch = 62 | time= 8.603358507156372 sec | loss= 76347.978828125\n",
      ">>> train | epoch = 63 | time= 8.4482581615448 sec | loss= 76348.016640625\n",
      ">>> train | epoch = 64 | time= 8.130694389343262 sec | loss= 76347.8051953125\n",
      ">>> train | epoch = 65 | time= 9.140697956085205 sec | loss= 76347.7879296875\n",
      ">>> train | epoch = 66 | time= 8.903236627578735 sec | loss= 76348.048671875\n",
      ">>> train | epoch = 67 | time= 9.107062339782715 sec | loss= 76347.74739583333\n",
      ">>> train | epoch = 68 | time= 8.893412590026855 sec | loss= 76347.88546875\n",
      ">>> train | epoch = 69 | time= 8.378362894058228 sec | loss= 76347.80985677084\n",
      ">>> train | epoch = 70 | time= 8.01888370513916 sec | loss= 76347.6550390625\n",
      ">>> train | epoch = 71 | time= 8.261402130126953 sec | loss= 76347.68412760417\n",
      ">>> train | epoch = 72 | time= 10.455623388290405 sec | loss= 76347.68438802083\n",
      ">>> train | epoch = 73 | time= 10.525007247924805 sec | loss= 76347.94325520833\n",
      ">>> train | epoch = 74 | time= 11.024555444717407 sec | loss= 76347.64270833334\n",
      ">>> train | epoch = 75 | time= 11.746384620666504 sec | loss= 76347.7171875\n",
      ">>> train | epoch = 76 | time= 10.741001844406128 sec | loss= 76347.65127604167\n",
      ">>> train | epoch = 77 | time= 10.575936317443848 sec | loss= 76347.67205729167\n",
      ">>> train | epoch = 78 | time= 10.39524793624878 sec | loss= 76347.60420572916\n",
      ">>> train | epoch = 79 | time= 10.511188745498657 sec | loss= 76347.561953125\n",
      ">>> train | epoch = 80 | time= 10.766151905059814 sec | loss= 76347.49713541666\n",
      ">>> train | epoch = 81 | time= 10.426654577255249 sec | loss= 76347.514765625\n",
      ">>> train | epoch = 82 | time= 10.819552421569824 sec | loss= 76347.41614583334\n",
      ">>> train | epoch = 83 | time= 10.5819251537323 sec | loss= 76347.9260546875\n",
      ">>> train | epoch = 84 | time= 10.58445692062378 sec | loss= 76347.4108203125\n",
      ">>> train | epoch = 85 | time= 10.467709302902222 sec | loss= 76347.53130208333\n",
      ">>> train | epoch = 86 | time= 10.649471521377563 sec | loss= 76347.371484375\n",
      ">>> train | epoch = 87 | time= 10.452415943145752 sec | loss= 76347.62791666666\n",
      ">>> train | epoch = 88 | time= 10.770004987716675 sec | loss= 76347.62950520833\n",
      ">>> train | epoch = 89 | time= 10.505110740661621 sec | loss= 76347.35438802083\n",
      ">>> train | epoch = 90 | time= 10.537914514541626 sec | loss= 76347.23477864583\n",
      ">>> train | epoch = 91 | time= 10.79440951347351 sec | loss= 76347.46729166666\n",
      ">>> train | epoch = 92 | time= 10.579633235931396 sec | loss= 76347.5046875\n",
      ">>> train | epoch = 93 | time= 10.549372434616089 sec | loss= 76347.4762890625\n",
      ">>> train | epoch = 94 | time= 10.236220121383667 sec | loss= 76347.5076953125\n",
      ">>> train | epoch = 95 | time= 10.12839961051941 sec | loss= 76347.4873046875\n",
      ">>> train | epoch = 96 | time= 10.565712690353394 sec | loss= 76347.3074609375\n",
      ">>> train | epoch = 97 | time= 10.684748649597168 sec | loss= 76347.66927083333\n",
      ">>> train | epoch = 98 | time= 10.801087141036987 sec | loss= 76347.4631640625\n",
      ">>> train | epoch = 99 | time= 10.245479106903076 sec | loss= 76347.194609375\n",
      "Training Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Started\")\n",
    "for i in range(epochs_start, epochs_end):\n",
    "    epoch = i + 1\n",
    "    loss_history['training'].append(0)\n",
    "    start_time = time.time()\n",
    "    for j, batch in enumerate(training_iterator):\n",
    "        with chainer.using_config('train', True):\n",
    "            x = concat_examples(batch=batch, device=device)\n",
    "            mean_z, ln_var_z, x, mean_x, ln_var_x = model(x)\n",
    "            loss = lossFunc(mean_z, ln_var_z, x, mean_x, ln_var_x)\n",
    "            model.cleargrads()\n",
    "            loss.backward()\n",
    "            optimizer.update()\n",
    "\n",
    "        loss_history['training'][-1] += float(loss.data)\n",
    "#         print('train=',j,' loss=',loss)\n",
    "    loss_history['training'][-1] /= j + 1\n",
    "    print('>>> train | epoch = {} | time= {} sec | loss= {}'.format(i, (time.time() - start_time), \n",
    "                                                        loss_history['training'][-1]))\n",
    "    training_iterator.reset()\n",
    "    if (epochs_end==epoch):\n",
    "        np.savez('{:s}/loss_history_ts_{:s}_{:03d}.npz'.format('Result', train_session, epoch), loss_history)\n",
    "        serializers.save_npz('{:s}/model_ts_{:s}_{:03d}.npz'.format('Result', train_session, epoch), model)\n",
    "        serializers.save_npz('{:s}/optimizer_ts_{:s}_{:03d}.npz'.format('Result', train_session, epoch), optimizer)\n",
    "    else:\n",
    "        np.savez('{:s}/loss_history_ts_{:s}_{:03d}.npz'.format(model_directory, train_session, epoch), loss_history)\n",
    "        serializers.save_npz('{:s}/model_ts_{:s}_{:03d}.npz'.format(model_directory, train_session, epoch), model)\n",
    "        serializers.save_npz('{:s}/optimizer_ts_{:s}_{:03d}.npz'.format(model_directory, train_session, epoch), optimizer)\n",
    "\n",
    "print(\"Training Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(loss_history['training'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0d2d13e390>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(15, 10))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(loss_history['training'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sameera/anaconda3/envs/NIPS/lib/python3.6/site-packages/ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    }
   ],
   "source": [
    "# encoder_T = Encoder()\n",
    "# decoder_T = Decoder()\n",
    "# model_T = Model(decoder_T, encoder_T) if device < 0 else Model(decoder_T, encoder_T).to_gpu(device)\n",
    "# serializers.load_npz('{:s}/model_ts_{:s}_{:03d}.npz'.format('Result', train_session, epochs_end), model_T)\n",
    "# lossFunc_T = Loss()\n",
    "\n",
    "batch_size = 1\n",
    "test_set = Mnist()\n",
    "test_iterator = SerialIterator(test_set, batch_size, False, True)\n",
    "\n",
    "test_history = []\n",
    "test_x = []\n",
    "test_mean_x = []\n",
    "test_var_x = []\n",
    "\n",
    "print('Test Starting...')\n",
    "for i in range(1):\n",
    "    epoch = i + 1\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for j, batch in enumerate(test_iterator):\n",
    "        with chainer.using_config('train', False):\n",
    "            x = concat_examples(batch=batch, device=device)\n",
    "            mean_z, ln_var_z, x, mean_x, ln_var_x = model(x)\n",
    "            loss = lossFunc(mean_z, ln_var_z, x, mean_x, ln_var_x)\n",
    "            test_x.append(x)\n",
    "            test_mean_x.append(mean_x)\n",
    "            test_var_x.append(ln_var_z)\n",
    "\n",
    "        test_history.append(float(loss.data))\n",
    "#         print('test epoch=',epoch,'test batch=',j,' loss=',loss)\n",
    "    np.savez('{:s}/test_loss_history_ts_{:s}_{:03d}.npz'.format('Result', train_session, epoch), test_history)\n",
    "print('Test Done...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2ba52b910c75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mout_x_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_mean_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m221\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "if device<0:\n",
    "    in_x_1  =      test_x[0][0].reshape(28,28)\n",
    "    out_x_1 = test_mean_x[0][0].data.reshape(28,28)\n",
    "\n",
    "    in_x_2  =      test_x[0][1].reshape(28,28)\n",
    "    out_x_2 = test_mean_x[0][1].data.reshape(28,28)\n",
    "else:\n",
    "    in_x_1  =      test_x[0][0].get().reshape(28,28)\n",
    "    out_x_1 = test_mean_x[0][0].data.get().reshape(28,28)\n",
    "\n",
    "    in_x_2  =      test_x[0][1].get().reshape(28,28)\n",
    "    out_x_2 = test_mean_x[0][1].data.get().reshape(28,28)\n",
    "\n",
    "fig=plt.figure(figsize=(10, 10))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.title('Input (1)')\n",
    "plt.imshow(in_x_1)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.title('output (1)')\n",
    "plt.imshow(out_x_1)\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.title('Input (2)')\n",
    "plt.imshow(in_x_2)\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.title('output (2)')\n",
    "plt.imshow(out_x_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EzCbq-7SKmBW"
   },
   "source": [
    "Bonus task: Try the same experiments on a different dataset. (20 bonus points)\n",
    "\n",
    "http://ruishu.io/2018/03/14/vae/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_His = np.load('{:s}/loss_history_ts_{:s}_{:03d}.npz'.format('Result', 'Adam', 20))\n",
    "loss_His = loss_His[loss_His.files[0]]\n",
    "loss_His = loss_His.reshape(1,)[0]\n",
    "\n",
    "fig=plt.figure(figsize=(15, 10))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(loss_His['training'])\n",
    "\n",
    "print(loss_His['training'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_His = np.load('{:s}/loss_history_ts_{:s}_{:03d}.npz'.format('Result', 'SGD', 20))\n",
    "loss_His = loss_His[loss_His.files[0]]\n",
    "loss_His = loss_His.reshape(1,)[0]\n",
    "\n",
    "fig=plt.figure(figsize=(15, 10))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(loss_His['training'])\n",
    "\n",
    "print(loss_His['training'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_His = np.load('{:s}/loss_history_ts_{:s}_{:03d}.npz'.format('Result', 'RMSprop', 20))\n",
    "loss_His = loss_His[loss_His.files[0]]\n",
    "loss_His = loss_His.reshape(1,)[0]\n",
    "\n",
    "fig=plt.figure(figsize=(15, 10))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(loss_His['training'])\n",
    "\n",
    "print(loss_His['training'][-1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "weeks_6_and_7",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
